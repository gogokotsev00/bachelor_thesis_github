\chapter{Problem analysis} \label{problem_analysis}
This chapter addresses some problems that this thesis tries to solve and analyses advantages and disadvantages of some strategies. It also includes information about which approaches serve as a model for our approach.

\section{Main Problems in the Area} \label{main_problems}
Camera placement optimisation has been a widely researched field for decades, because it is a complicated task, involves different and does not have an exact solution. There are numerous works which propose their own strategies and in this way contribute to constant progress in the area. We are now going to discuss some of the main problems this thesis is concerned with.

To begin with, when the focus is on the traffic and its participants, surveillance cameras should be able to efficiently recognise each object, in order to be aware of its position, size, speed, etc. Using 3D object detection, they should aid autonomous vehicles in collision prevention or path planning. However, a major setback is that traffic is dynamic and objects are constantly moving, some of which are larger than others and therefore create a blind zone in the camera's field of view. This phenomenon is effected by traffic conditions and changes depending on the vehicles passing through. Furthermore, occlusion that falls in the field of view causes a great impact on performance of directional sensors, like cameras, because it prevents them from an accurate and clear perception of the environment. One study that tries to handle this issue is \cite{occlusion_degree_model} (see \ref{related_work}) where they propose a mathematical model, which describes this behaviour in a 3D space. With the help of various metrics, they examine how large-sized 'occluder' vehicles impede the view to other 'target' vehicles and thus decrease object detection's ability of a camera, for example. They prove that traffic density and presence of trucks lead to performance loss, which means that modern object detection algorithms, some of which studied in \cite{camera_vs_lidar} and \cite{object_detection_list}, used by monocular cameras and precisely for 2D images are limited to the sensor's not disrupted sight. What is more, they lack depth information, which makes the work of algorithms complicated, because only 2D methods for object detection could be applied, which mostly require a non-occluded view to the target. Although there are now algorithms, which use trained neural networks to work with occlusions like \cite{object_detection_alg}, their results are still not fully accurate and precise when an object stays in front of a target.

Another major issue is the height at which a camera should be positioned in order to have a maximal coverage of the region of interest. Height plays a big role in traffic surveillance, because a higher position means more vehicles monitored and less occlusion caught by the sensor. If, for instance, the roadside camera is placed on a position lower than a truck's height, this position is suboptimal due to an increased chance of perceived occlusions. There has been less previous evidence for estimating an optimal height value when solving the optimal camera placement problem. Moreover, many works provide solutions for the issue, where they do not consider the camera height as a factor and its impact on the evaluation, which is the case for Ma et al. in \cite{surveillance_related_work} where they divide Beijing into blocks and thus calculate the possible locations for a block in which a camera could be placed. They use five placement strategies for their experiments, which they solve with greedy algorithms and theoretical lower bounds, but do not suggest a height for their cameras. In \cite{total_coverage_optimum} they use directional and omnidirectional cameras in an Occupancy Grid Map to find the minimum of them needed for a total coverage without providing any information about the distance between sensor and ground. In other works like \cite{max_camera_coverage} and \cite{genetic_alg} experiments were also focused on other heuristic strategies for achieving full road coverage, not regarding which is the optimal height for their sensors to be fixed at. However, there are some researches out of and from the area of camera placement optimisation, which include camera's height in their results. For example, in a study for multi-camera traffic scene mosaic based on camera calibration \cite{multi_camera_calib} the researchers have placed their single camera at 6.18 m, which is under the ideal 8-12 meters proposed by a webpage for fixed camera's requirements\footnote{\url{https://help.goodvisionlive.com/en/articles/3304475-requirements-for-fixed-camera-video-processing}, visited on 06/12/2022}. For the purpose of camera calibration from moving objects in traffic surveillance, Zhang et al. positioned in \cite{practical_camera_calib} a camera at 7,42 m to recover its extrinsic and intrinsic camera parameters using data from the objects.  

\section{Problems as Inspiration for our Approach}
In the first paragraph of \ref{main_problems} it was discussed the despite being extensively and constantly further developed, object detection algorithms are still immature and could not achieve full accuracy in their estimations, especially in the field of 2D object recognition, where no depth data is available and occlusions occur. For sensors whose role is to improve the connected and automated mobility, there is no place for incorrect evaluations, which are mostly caused by objects that fall into the sensor's field of view. In the following chapter \ref{approach} is discussed a solution on how an instance segmentation camera could provide ground-truth data independent of occlusions. Additionally, we simulate in ideal weather conditions and without distortions in the images in order to obtain precise evaluation of an occlusion degree.

As it can be seen, exact information regarding the optimal height for a traffic camera appears to be missing in many from the found sources or there is no structured approach about how to calculate it. It is important to take camera height into account when conducting experiments, because it impacts aspects like field of view and number of estimated occlusions. Therefore, in this work we are going to examine how the camera's performance changes at different elevation options and provide results. The approach for finding an optimal height value and location for a camera is outlined in the next chapter.
