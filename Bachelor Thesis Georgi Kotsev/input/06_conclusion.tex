\chapter{Conclusion and Future Work}
\label{conclusion}
%#############################################################
%###################### Summary   ############################
%#############################################################
\section{Summary}
% DELETEME: put a plain summary of your work here. Summaries should be made of each Chapter beginning with Chapter~2 and ending with you evaluation. Just write down what you did and describe the corresponding results without reflecting on them.
At the beginning of this work, we reflect on important scientific information as basis for understanding of the solution we propose. Additionally, we mention various studies in the area of camera placement optimisation, describe their strategies for solving the issue and explain that the ODM of Du et al. in \cite{occlusion_degree_model} serves as inspiration for our approach. Afterwards, in Chapter \ref{problem_analysis} we outline main problems found in the literature during our research. Information about which height should be aimed for and how to decrease occlusion between vehicles are the challenges this thesis was concerned with. In order to investigate which camera positioning is optimal, we present an approach, which includes a 3D simulator as testing environment, two vehicles of equal or different size and an instance segmentation camera. Moreover, the meaning behind our experiments was to see which out of 8 randomly chosen positions is efficient in detecting less occlusions. To provide an insight into our implementation, Chapter \ref{implementation} describes in detail which functionalities of CARLA were used and how our simulation pipeline works, which consists of 3 stages - Data generation, Experiment conduction, Result Evaluation. At the end of the fifth chapter, we discuss our two metrics for comparison of cameras' performance, where the focus is on the number of detected occlusions and those which exceeded a certain threshold (see Section \ref{subsec:metrics}). During the evaluation part, we chose heatmaps and tables to visualise the results, which we then analyse and evaluate. Finally, use the heatmaps and the scores of both metrics to draw a conclusion that positions 3 and 7 outperform the other ones. Some critics for the efficiency of our metrics are provided at the end of Chapter \ref{evaluation}. 

%#############################################################
%###################### Conclusion ###########################
%#############################################################
\section{Conclusion}
% DELETEME: do not summarize here. Reflect on the results that you have achieved. What might be the reasons and meanings of these? Did you make improvements in comparison to the state of the art? What are the good points about your results and work? What are the drawbacks?
Our approach was successful in determining positions for an efficient traffic camera and defining 8 meters as a minimal height. In comparison to studies like \cite{total_coverage_optimum} and \cite{max_camera_coverage} our strategy involves more than one static occlusion, which is examined in a 3D simulator and in this way we provide an enhanced generic approach, which can be applied everywhere. Another benefit of our work is that the impact of height on camera has been tested, which showed that a higher position detects fewer occlusions and have a more accurate view over the road. What is more, in our implementation we used CARLA's instance segmentation camera, which generates ground-truth data and eliminates the necessity of an object detection algorithm. However, if our proposal is to be involved in real-world experiments, depth information should be available and also an algorithm for object recognition must be integrated, because there will be a difference compared to the simulated environment where access to the attributes of each object can be gained. Although our simulations try to approximate dynamic occlusion, they still remain in the area of static experiments. Therefore, if a dynamic scenario has to be represented accurately, the distance between target vehicle spawn locations should be set at least to 0.5 m, which in our experiments is 3 m. What is more, for such shorter distance our algorithm will be slow, especially when large-sized vehicles participate. The reason for this is that we go through 2D arrays of pixels, and therefore either the implementation should be optimised or the constraint for placing occluders, so that only occlusions are perceived by the camera. Nevertheless, our strategy can still provide accurate results for various scenarios, when it is applied in future studies. Some aspects still need to be added, if real-world conditions should be reproduced precisely, which is discussed in the following section.

%#############################################################
%###################### Future Work ##########################
%#############################################################
\section{Future Work}
% DELETEME: Regarding your results - which problems did you not solve? Which questions are still open? Which new questions arose? How should someone / would you continue working in your thesis field basing on your results?

After inspecting the results, we were able to solve the two issues we discussed in the problem analysis. Nevertheless, our approach is focused only on static occlusion and ground truth data, while still lacking some necessary factors for plausible camera performance. For instance, in the future it can be extended by using more vehicles in the simulations in order to observe how traffic density affects object detection and occlusion occurrences. Having mentioned object detection, it is important to implement one of the latest algorithms to see how much time a camera needs to notice a vehicle and combined with our M1 metric it can be realised above what occlusion degree a vehicle is no more visible. By now, we have results for only one camera, therefore further ones can be added to increase the field of view and decrease occlusion by having different points of view. The last suggestion would be to implement some camera constraints as severe weather conditions or image distortion, which will be responsible for reproducing a real-world behaviour.