\chapter{Conclusion and Future Work}
\label{conclusion}
%#############################################################
%###################### Summary   ############################
%#############################################################
\section{Summary}
% DELETEME: put a plain summary of your work here. Summaries should be made of each Chapter beginning with Chapter~2 and ending with you evaluation. Just write down what you did and describe the corresponding results without reflecting on them.
In this work, we started by reflecting on important scientific information as background for understanding the solution we propose. Additionally, we mentioned various studies in the area of camera placement optimisation, described their strategies for solving the issue and explained that the ODM of Du et al. in \cite{occlusion_degree_model} served as inspiration for our approach. Afterwards, in Chapter \ref{problem_analysis} we outlined main problems found in the literature during our research. Information about which height should be aimed for and little number of view-obstructors in an experiment are the issues this thesis was concerned with. In order to investigate which camera positioning is optimal, we presented an approach, which included a 3D simulator as testing environment, two test vehicles and an instance segmentation camera. Moreover, the meaning behind our experiments was to see which out of 8 randomly chosen positions is efficient in detecting less occlusions. To provide an insight into our implementation, Chapter \ref{implementation} described in detail which functionalities of CARLA were used and how our simulation pipeline works, which consists of 3 stages - Data generation, Experiment conduction, Result Evaluation. At the end of the fifth chapter, we discussed two metrics for comparison of cameras' performance, where the focus is on the number of detected occlusions and those which exceeded a certain threshold (see Section \ref{subsec:metrics}). During the evaluation part, we chose heatmaps and tables to visualise the results, then analysed them and drew a conclusion that positions 3 and 7 outperform the other ones by taking scores from both metrics M1 and M2 into consideration.

%#############################################################
%###################### Conclusion ###########################
%#############################################################
\section{Conclusion}
% DELETEME: do not summarize here. Reflect on the results that you have achieved. What might be the reasons and meanings of these? Did you make improvements in comparison to the state of the art? What are the good points about your results and work? What are the drawbacks?
Our approach was successful in determining positions for an efficient traffic camera and defining 8 meters as a minimal height. In comparison to studies like \cite{total_coverage_optimum} and \cite{max_camera_coverage} our strategy involved considering static occlusion in many spawn locations and in this way we provide an enhanced generic approach, which is applicable everywhere. Another benefit of our work is that impact of height on camera was tested, which showed that a higher position detects fewer occlusions and have a more accurate view over the road. What is more, in our implementation we used CARLA's instance segmentation camera, which generates ground-truth data and eliminates the necessity of an object detection algorithm. However, if our proposal is to be involved in real-world experiments, depth information should be available and also an algorithm for object recognition must be integrated, because there will be a difference compared to the simulated environment where each object ca n be accessed. Although our simulations try to approximate dynamic occlusion, they still remain in the area of static experiments. In our experiments, the distance between target vehicle spawn locations is 3 m which can be decreased to 0.5 m, if a dynamic scenario has to be represented accurately. What is more, for such shorter distance our algorithm will be slow, especially when large-sized vehicles participate. 

%#############################################################
%###################### Future Work ##########################
%#############################################################
\section{Future Work}
% DELETEME: Regarding your results - which problems did you not solve? Which questions are still open? Which new questions arose? How should someone / would you continue working in your thesis field basing on your results?

After inspecting the results, we were able to solve the two issues we discussed in the problem analysis. Nevertheless, our approach is focused only on static occlusion and ground truth data, while still lacking some necessary factors for plausible camera performance. For instance, in the future it can be extended by using more vehicles in the simulations in order to observe how traffic density affects object detection and occlusion occurrences. Having mentioned object detection, it is important to implement one of the latest algorithms to see how much time a camera needs to notice a vehicle and combined with our M1 metric it can be realised above what occlusion degree a vehicle is no more visible. By now, we have results for only one camera, therefore further ones can be added to increase the field of view and decrease occlusion by having different points of view. The last suggestion would be to implement some camera constraints as severe weather conditions or image distortion, which will be responsible for reproducing a real-world behaviour.